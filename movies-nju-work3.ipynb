{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 11717209,
     "sourceType": "datasetVersion",
     "datasetId": 7355126
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Define file paths\n",
    "train_path = '/kaggle/input/movie-data/recommendation-ratings-train.txt'\n",
    "test_path = '/kaggle/input/movie-data/recommendation-ratings-test.txt'\n",
    "\n",
    "# Load the data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load rating data from file\"\"\"\n",
    "    columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(file_path, sep='\\t', names=columns)\n",
    "    return data\n",
    "\n",
    "# Load train and test data\n",
    "train_data = load_data(train_path)\n",
    "test_data = load_data(test_path)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# Display first few rows of training data\n",
    "print(\"\\nTraining data sample:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nTraining data statistics:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(train_data.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# Visualize rating distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=train_data)\n",
    "plt.title('Rating Distribution in Training Data')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Create user-item matrices\n",
    "def create_matrix(data):\n",
    "    \"\"\"Create a user-item matrix from the data\"\"\"\n",
    "    return data.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "user_item_matrix_train = create_matrix(train_data)\n",
    "print(\"\\nUser-Item Matrix Shape (Train):\", user_item_matrix_train.shape)\n",
    "\n",
    "# Check sparsity\n",
    "sparsity = 100 * (1 - user_item_matrix_train.count().sum() / \n",
    "                 (user_item_matrix_train.shape[0] * user_item_matrix_train.shape[1]))\n",
    "print(f\"Matrix Sparsity: {sparsity:.2f}%\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class UserCF:\n",
    "    def __init__(self, similarity_method='pearson', k=30):\n",
    "        \"\"\"\n",
    "        Initialize User-based Collaborative Filtering\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        similarity_method : str\n",
    "            Method to calculate similarity ('pearson' or 'cosine')\n",
    "        k : int\n",
    "            Number of neighbors to consider\n",
    "        \"\"\"\n",
    "        self.similarity_method = similarity_method\n",
    "        self.k = k\n",
    "        self.user_similarity = None\n",
    "        self.user_item_matrix = None\n",
    "\n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"\n",
    "        Fit the model with user-item matrix\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_item_matrix : pandas.DataFrame\n",
    "            User-item matrix with users as index and items as columns\n",
    "        \"\"\"\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "\n",
    "        # Calculate user similarity matrix\n",
    "        if self.similarity_method == 'pearson':\n",
    "            self.user_similarity = self.user_item_matrix.T.corr(method='pearson')\n",
    "        elif self.similarity_method == 'cosine':\n",
    "            # Normalize the data for cosine similarity\n",
    "            normalized_matrix = self.user_item_matrix.subtract(self.user_item_matrix.mean(axis=1), axis=0)\n",
    "            # Fill NaN with 0 for dot product calculation\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            similarity_matrix = pd.DataFrame(index=self.user_item_matrix.index, \n",
    "                                            columns=self.user_item_matrix.index)\n",
    "\n",
    "            for i in self.user_item_matrix.index:\n",
    "                for j in self.user_item_matrix.index:\n",
    "                    user1 = normalized_matrix.loc[i].values\n",
    "                    user2 = normalized_matrix.loc[j].values\n",
    "\n",
    "                    # Calculate dot product\n",
    "                    dot_product = np.dot(user1, user2)\n",
    "\n",
    "                    # Calculate magnitudes\n",
    "                    magnitude1 = np.sqrt(np.dot(user1, user1))\n",
    "                    magnitude2 = np.sqrt(np.dot(user2, user2))\n",
    "\n",
    "                    # Calculate cosine similarity\n",
    "                    if magnitude1 * magnitude2 == 0:\n",
    "                        similarity_matrix.loc[i, j] = 0\n",
    "                    else:\n",
    "                        similarity_matrix.loc[i, j] = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "            self.user_similarity = similarity_matrix\n",
    "\n",
    "        print(f\"User similarity matrix shape: {self.user_similarity.shape}\")\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"\n",
    "        Predict rating for a user-item pair\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int\n",
    "            User ID\n",
    "        item_id : int\n",
    "            Item ID\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Predicted rating\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_item_matrix.index or item_id not in self.user_item_matrix.columns:\n",
    "            # If user or item not in training data, return global mean\n",
    "            return self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Get users who rated this item\n",
    "        users_rated_item = self.user_item_matrix[item_id].dropna().index\n",
    "\n",
    "        if len(users_rated_item) == 0:\n",
    "            # If no user rated this item, return user's mean rating\n",
    "            user_mean = self.user_item_matrix.loc[user_id].mean()\n",
    "            return user_mean if not np.isnan(user_mean) else self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Get similarity scores for these users\n",
    "        if user_id in self.user_similarity.index:\n",
    "            similarities = self.user_similarity.loc[user_id, users_rated_item]\n",
    "        else:\n",
    "            # If user not in similarity matrix, return global mean\n",
    "            return self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Select top-k neighbors\n",
    "        if len(similarities) > self.k:\n",
    "            top_k_users = similarities.nlargest(self.k).index\n",
    "        else:\n",
    "            top_k_users = similarities.index\n",
    "\n",
    "        # Calculate weighted average of ratings\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "\n",
    "        for neighbor in top_k_users:\n",
    "            if item_id in self.user_item_matrix.columns and not np.isnan(self.user_item_matrix.loc[neighbor, item_id]):\n",
    "                sim_score = self.user_similarity.loc[user_id, neighbor]\n",
    "                rating = self.user_item_matrix.loc[neighbor, item_id]\n",
    "\n",
    "                numerator += sim_score * rating\n",
    "                denominator += abs(sim_score)\n",
    "\n",
    "        if denominator == 0:\n",
    "            # If no valid neighbors, return user's mean rating\n",
    "            user_mean = self.user_item_matrix.loc[user_id].mean()\n",
    "            return user_mean if not np.isnan(user_mean) else self.user_item_matrix.stack().mean()\n",
    "\n",
    "        return numerator / denominator\n",
    "\n",
    "    def predict_all(self, test_data):\n",
    "        \"\"\"\n",
    "        Predict ratings for all user-item pairs in test data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_data : pandas.DataFrame\n",
    "            Test data with userId, movieId columns\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.Series\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in test_data.iterrows():\n",
    "            user_id = row['userId']\n",
    "            item_id = row['movieId']\n",
    "            pred = self.predict(user_id, item_id)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        return pd.Series(predictions)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "class ItemCF:\n",
    "    def __init__(self, similarity_method='pearson', k=30):\n",
    "        \"\"\"\n",
    "        Initialize Item-based Collaborative Filtering\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        similarity_method : str\n",
    "            Method to calculate similarity ('pearson' or 'cosine')\n",
    "        k : int\n",
    "            Number of neighbors to consider\n",
    "        \"\"\"\n",
    "        self.similarity_method = similarity_method\n",
    "        self.k = k\n",
    "        self.item_similarity = None\n",
    "        self.user_item_matrix = None\n",
    "\n",
    "    def fit(self, user_item_matrix):\n",
    "        \"\"\"\n",
    "        Fit the model with user-item matrix\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_item_matrix : pandas.DataFrame\n",
    "            User-item matrix with users as index and items as columns\n",
    "        \"\"\"\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "\n",
    "        # Calculate item similarity matrix\n",
    "        if self.similarity_method == 'pearson':\n",
    "            self.item_similarity = self.user_item_matrix.corr(method='pearson')\n",
    "        elif self.similarity_method == 'cosine':\n",
    "            # Normalize the data for cosine similarity\n",
    "            normalized_matrix = self.user_item_matrix.subtract(self.user_item_matrix.mean(axis=0), axis=1)\n",
    "            # Fill NaN with 0 for dot product calculation\n",
    "            normalized_matrix = normalized_matrix.fillna(0)\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            similarity_matrix = pd.DataFrame(index=self.user_item_matrix.columns, \n",
    "                                            columns=self.user_item_matrix.columns)\n",
    "\n",
    "            for i in self.user_item_matrix.columns:\n",
    "                for j in self.user_item_matrix.columns:\n",
    "                    item1 = normalized_matrix[i].values\n",
    "                    item2 = normalized_matrix[j].values\n",
    "\n",
    "                    # Calculate dot product\n",
    "                    dot_product = np.dot(item1, item2)\n",
    "\n",
    "                    # Calculate magnitudes\n",
    "                    magnitude1 = np.sqrt(np.dot(item1, item1))\n",
    "                    magnitude2 = np.sqrt(np.dot(item2, item2))\n",
    "\n",
    "                    # Calculate cosine similarity\n",
    "                    if magnitude1 * magnitude2 == 0:\n",
    "                        similarity_matrix.loc[i, j] = 0\n",
    "                    else:\n",
    "                        similarity_matrix.loc[i, j] = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "            self.item_similarity = similarity_matrix\n",
    "\n",
    "        print(f\"Item similarity matrix shape: {self.item_similarity.shape}\")\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"\n",
    "        Predict rating for a user-item pair\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_id : int\n",
    "            User ID\n",
    "        item_id : int\n",
    "            Item ID\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Predicted rating\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_item_matrix.index or item_id not in self.user_item_matrix.columns:\n",
    "            # If user or item not in training data, return global mean\n",
    "            return self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Get items rated by this user\n",
    "        items_rated_by_user = self.user_item_matrix.loc[user_id].dropna().index\n",
    "\n",
    "        if len(items_rated_by_user) == 0:\n",
    "            # If user hasn't rated any items, return item's mean rating\n",
    "            item_mean = self.user_item_matrix[item_id].mean()\n",
    "            return item_mean if not np.isnan(item_mean) else self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Get similarity scores for these items\n",
    "        if item_id in self.item_similarity.index:\n",
    "            similarities = self.item_similarity.loc[item_id, items_rated_by_user]\n",
    "        else:\n",
    "            # If item not in similarity matrix, return global mean\n",
    "            return self.user_item_matrix.stack().mean()\n",
    "\n",
    "        # Select top-k neighbors\n",
    "        if len(similarities) > self.k:\n",
    "            top_k_items = similarities.nlargest(self.k).index\n",
    "        else:\n",
    "            top_k_items = similarities.index\n",
    "\n",
    "        # Calculate weighted average of ratings\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "\n",
    "        for neighbor in top_k_items:\n",
    "            if neighbor in self.user_item_matrix.columns and not np.isnan(self.user_item_matrix.loc[user_id, neighbor]):\n",
    "                sim_score = self.item_similarity.loc[item_id, neighbor]\n",
    "                rating = self.user_item_matrix.loc[user_id, neighbor]\n",
    "\n",
    "                numerator += sim_score * rating\n",
    "                denominator += abs(sim_score)\n",
    "\n",
    "        if denominator == 0:\n",
    "            # If no valid neighbors, return item's mean rating\n",
    "            item_mean = self.user_item_matrix[item_id].mean()\n",
    "            return item_mean if not np.isnan(item_mean) else self.user_item_matrix.stack().mean()\n",
    "\n",
    "        return numerator / denominator\n",
    "\n",
    "    def predict_all(self, test_data):\n",
    "        \"\"\"\n",
    "        Predict ratings for all user-item pairs in test data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_data : pandas.DataFrame\n",
    "            Test data with userId, movieId columns\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        pandas.Series\n",
    "            Predicted ratings\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in test_data.iterrows():\n",
    "            user_id = row['userId']\n",
    "            item_id = row['movieId']\n",
    "            pred = self.predict(user_id, item_id)\n",
    "            predictions.append(pred)\n",
    "\n",
    "        return pd.Series(predictions)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def evaluate_model(model, test_data, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate model using RMSE\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : object\n",
    "        Model with predict_all method\n",
    "    test_data : pandas.DataFrame\n",
    "        Test data with userId, movieId, rating columns\n",
    "    model_name : str\n",
    "        Name of the model for display\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        RMSE score\n",
    "    pandas.Series\n",
    "        Predictions\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict_all(test_data)\n",
    "    end_time = time.time()\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(test_data['rating'], predictions))\n",
    "\n",
    "    print(f\"{model_name} RMSE: {rmse:.4f}\")\n",
    "    print(f\"{model_name} Prediction Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    return rmse, predictions\n",
    "\n",
    "# Train and evaluate User-CF with Pearson correlation\n",
    "print(\"\\n--- User-based CF with Pearson Correlation ---\")\n",
    "user_cf_pearson = UserCF(similarity_method='pearson', k=30)\n",
    "user_cf_pearson.fit(user_item_matrix_train)\n",
    "rmse_user_cf_pearson, pred_user_cf_pearson = evaluate_model(user_cf_pearson, test_data, \"User-CF (Pearson)\")\n",
    "\n",
    "# Train and evaluate User-CF with Cosine similarity\n",
    "print(\"\\n--- User-based CF with Cosine Similarity ---\")\n",
    "user_cf_cosine = UserCF(similarity_method='cosine', k=30)\n",
    "user_cf_cosine.fit(user_item_matrix_train)\n",
    "rmse_user_cf_cosine, pred_user_cf_cosine = evaluate_model(user_cf_cosine, test_data, \"User-CF (Cosine)\")\n",
    "\n",
    "# Train and evaluate Item-CF with Pearson correlation\n",
    "print(\"\\n--- Item-based CF with Pearson Correlation ---\")\n",
    "item_cf_pearson = ItemCF(similarity_method='pearson', k=30)\n",
    "item_cf_pearson.fit(user_item_matrix_train)\n",
    "rmse_item_cf_pearson, pred_item_cf_pearson = evaluate_model(item_cf_pearson, test_data, \"Item-CF (Pearson)\")\n",
    "\n",
    "# Train and evaluate Item-CF with Cosine similarity\n",
    "print(\"\\n--- Item-based CF with Cosine Similarity ---\")\n",
    "item_cf_cosine = ItemCF(similarity_method='cosine', k=30)\n",
    "item_cf_cosine.fit(user_item_matrix_train)\n",
    "rmse_item_cf_cosine, pred_item_cf_cosine = evaluate_model(item_cf_cosine, test_data, \"Item-CF (Cosine)\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Compare RMSE scores\n",
    "models = ['User-CF (Pearson)', 'User-CF (Cosine)', 'Item-CF (Pearson)', 'Item-CF (Cosine)']\n",
    "rmse_scores = [rmse_user_cf_pearson, rmse_user_cf_cosine, rmse_item_cf_pearson, rmse_item_cf_cosine]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(models, rmse_scores, color=['blue', 'skyblue', 'green', 'lightgreen'])\n",
    "plt.title('RMSE Comparison of Different Recommendation Algorithms')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('RMSE (lower is better)')\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize prediction distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(pred_user_cf_pearson, bins=20, kde=True)\n",
    "plt.title('User-CF (Pearson) Predictions')\n",
    "plt.xlabel('Predicted Rating')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(pred_user_cf_cosine, bins=20, kde=True)\n",
    "plt.title('User-CF (Cosine) Predictions')\n",
    "plt.xlabel('Predicted Rating')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(pred_item_cf_pearson, bins=20, kde=True)\n",
    "plt.title('Item-CF (Pearson) Predictions')\n",
    "plt.xlabel('Predicted Rating')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(pred_item_cf_cosine, bins=20, kde=True)\n",
    "plt.title('Item-CF (Cosine) Predictions')\n",
    "plt.xlabel('Predicted Rating')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze prediction errors\n",
    "def analyze_errors(true_ratings, predictions, model_name):\n",
    "    errors = predictions - true_ratings\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(errors, bins=20, kde=True)\n",
    "    plt.title(f'Error Distribution for {model_name}')\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n{model_name} Error Statistics:\")\n",
    "    print(f\"Mean Error: {errors.mean():.4f}\")\n",
    "    print(f\"Std Dev of Error: {errors.std():.4f}\")\n",
    "    print(f\"Max Overestimation: {errors.max():.4f}\")\n",
    "    print(f\"Max Underestimation: {errors.min():.4f}\")\n",
    "\n",
    "# Analyze errors for each model\n",
    "analyze_errors(test_data['rating'], pred_user_cf_pearson, \"User-CF (Pearson)\")\n",
    "analyze_errors(test_data['rating'], pred_user_cf_cosine, \"User-CF (Cosine)\")\n",
    "analyze_errors(test_data['rating'], pred_item_cf_pearson, \"Item-CF (Pearson)\")\n",
    "analyze_errors(test_data['rating'], pred_item_cf_cosine, \"Item-CF (Cosine)\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def tune_k(model_class, similarity_method, k_values, user_item_matrix, test_data, model_name):\n",
    "    \"\"\"\n",
    "    Tune the number of neighbors (k) for CF models\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_class : class\n",
    "        Class of the model (UserCF or ItemCF)\n",
    "    similarity_method : str\n",
    "        Similarity method to use\n",
    "    k_values : list\n",
    "        List of k values to try\n",
    "    user_item_matrix : pandas.DataFrame\n",
    "        User-item matrix\n",
    "    test_data : pandas.DataFrame\n",
    "        Test data\n",
    "    model_name : str\n",
    "        Name of the model for display\n",
    "    \"\"\"\n",
    "    rmse_scores = []\n",
    "\n",
    "    for k in k_values:\n",
    "        model = model_class(similarity_method=similarity_method, k=k)\n",
    "        model.fit(user_item_matrix)\n",
    "        rmse, _ = evaluate_model(model, test_data, f\"{model_name} (k={k})\")\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    # Plot RMSE vs k\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_values, rmse_scores, marker='o')\n",
    "    plt.title(f'RMSE vs Number of Neighbors (k) for {model_name}')\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('RMSE (lower is better)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Find best k\n",
    "    best_idx = np.argmin(rmse_scores)\n",
    "    best_k = k_values[best_idx]\n",
    "    best_rmse = rmse_scores[best_idx]\n",
    "\n",
    "    print(f\"\\nBest k for {model_name}: {best_k} with RMSE: {best_rmse:.4f}\")\n",
    "\n",
    "    return best_k, best_rmse\n",
    "\n",
    "# Define k values to try\n",
    "k_values = [5, 10, 20, 30, 50, 70, 100]\n",
    "\n",
    "# Tune k for User-CF with Pearson correlation\n",
    "print(\"\\n--- Tuning k for User-CF (Pearson) ---\")\n",
    "best_k_user_pearson, best_rmse_user_pearson = tune_k(\n",
    "    UserCF, 'pearson', k_values, user_item_matrix_train, test_data, \"User-CF (Pearson)\")\n",
    "\n",
    "# Tune k for Item-CF with Pearson correlation\n",
    "print(\"\\n--- Tuning k for Item-CF (Pearson) ---\")\n",
    "best_k_item_pearson, best_rmse_item_pearson = tune_k(\n",
    "    ItemCF, 'pearson', k_values, user_item_matrix_train, test_data, \"Item-CF (Pearson)\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "print(\"\\n--- Recommendation System Comparison Summary ---\")\n",
    "print(\"\\nRMSE Scores:\")\n",
    "for model, rmse in zip(models, rmse_scores):\n",
    "    print(f\"{model}: {rmse:.4f}\")\n",
    "\n",
    "print(\"\\nBest Models After Tuning:\")\n",
    "print(f\"User-CF (Pearson) with k={best_k_user_pearson}: RMSE = {best_rmse_user_pearson:.4f}\")\n",
    "print(f\"Item-CF (Pearson) with k={best_k_item_pearson}: RMSE = {best_rmse_item_pearson:.4f}\")\n",
    "\n",
    "# Determine the overall best model\n",
    "best_model_idx = np.argmin([best_rmse_user_pearson, best_rmse_item_pearson])\n",
    "best_model_name = [\"User-CF (Pearson)\", \"Item-CF (Pearson)\"][best_model_idx]\n",
    "best_model_k = [best_k_user_pearson, best_k_item_pearson][best_model_idx]\n",
    "best_model_rmse = [best_rmse_user_pearson, best_rmse_item_pearson][best_model_idx]\n",
    "\n",
    "print(f\"\\nOverall Best Model: {best_model_name} with k={best_model_k} (RMSE = {best_model_rmse:.4f})\")\n",
    "\n",
    "# Final observations\n",
    "print(\"\\nFinal Observations:\")\n",
    "print(\"1. We implemented and compared User-based and Item-based collaborative filtering algorithms.\")\n",
    "print(f\"2. We evaluated the models using RMSE and found that {best_model_name} performed best.\")\n",
    "print(\"3. We tuned the number of neighbors (k) and found optimal values for each algorithm.\")\n",
    "print(\"4. The visualization of rating distributions and prediction errors provided insights into model behavior.\")\n",
    "print(\"5. Future improvements could include matrix factorization methods, hybrid approaches, or deep learning models.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
